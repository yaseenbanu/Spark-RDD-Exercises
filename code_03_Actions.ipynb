{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [collect()](#toc1_)    \n",
    "- [count()](#toc2_)    \n",
    "- [take(n)](#toc3_)    \n",
    "- [first()](#toc4_)    \n",
    "- [takeSample(withReplacement, num, [seed])](#toc5_)    \n",
    "- [takeOrdered(num, [key])](#toc6_)    \n",
    "- [saveAsTextFile(path)](#toc7_)    \n",
    "- [saveAsSequenceFile(path)](#toc8_)    \n",
    "- [countByKey()](#toc9_)    \n",
    "- [foreach(func)](#toc10_)    \n",
    "- [reduce(func)](#toc11_)    \n",
    "- [fold(zeroValue)(func)](#toc12_)    \n",
    "- [aggregate(zeroValue)(seqOp, combOp)](#toc13_)    \n",
    "- [collectAsMap()](#toc14_)    \n",
    "- [lookup(key)](#toc15_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD-Examples\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[collect()](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.collect()\n",
    "print(result)  # Output: [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[count()](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.count()\n",
    "print(result)  # Output: 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[take(n)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Take action: Retrieve the n elements of the RDD\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.take(2)\n",
    "print(result)  # Output: [1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RDD of integers\n",
    "rdd = sc.parallelize([5, 7, 3, 9, 1])\n",
    "\n",
    "# use take() to get the first 3 elements of the RDD\n",
    "take_result = rdd.take(3)\n",
    "\n",
    "print(\"First 3 elements:\", take_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RDD of integers\n",
    "rdd = sc.parallelize([5, 7, 3, 9, 1])\n",
    "\n",
    "# use top() to get the top 3 elements of the RDD\n",
    "top_result = rdd.top(3)\n",
    "\n",
    "# print the results\n",
    "print(\"Top 3 elements:\", top_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[first()](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# First action: Retrieve the first element of the RDD\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.first()\n",
    "print(result)  # Output: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[takeSample(withReplacement, num, [seed])](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "result = rdd.takeSample(False, 3)\n",
    "print(result)  # Output: a random subset of 3 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list which takes 3 arguments:\n",
    "# 1. Whether to repeat the already taken elements\n",
    "# 2. Number of elements which you  want to take\n",
    "# 3. Seed value\n",
    "\n",
    "# Case 1: When the wanted values greater then the original sample size, we can see duplicate values\n",
    "\n",
    "rdd = sc.parallelize(range(1,10)).takeSample(True,11,23)\n",
    "\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: When the wanted values greater then the original sample size, we will see the original array\n",
    "\n",
    "rdd = sc.parallelize(range(1,10)).takeSample(False,50,1)\n",
    "\n",
    "rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[takeOrdered(num, [key])](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([5, 2, 3, 1, 4])\n",
    "result = rdd.takeOrdered(3)\n",
    "print(result)  # Output: [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[saveAsTextFile(path)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "rdd.saveAsTextFile(\"./data/output/output.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[saveAsSequenceFile(path)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('b', 2)])\n",
    "rdd.saveAsSequenceFile(\"./data/output/output.seq\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[countByKey()](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'a': 2, 'b': 1})\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('b', 2), ('a', 3)])\n",
    "result = rdd.countByKey()\n",
    "print(result)  # Output: {'a': 2, 'b': 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[foreach(func)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "rdd.foreach(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc11_'></a>[reduce(func)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.reduce(lambda a, b: a + b)\n",
    "print(result)  # Output: 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc12_'></a>[fold(zeroValue)(func)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.fold(0, lambda a, b: a + b)\n",
    "print(result)  # Output: 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "total_sum = rdd.fold(100, lambda acc, x: acc + x)\n",
    "print(total_sum) # This Prints 515\n",
    "\n",
    "rdd2 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "total_sum = rdd.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This Prints 65\n",
    "\n",
    "rdd3 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "total_sum = rdd.fold(0, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 15\n",
    "\n",
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],1)\n",
    "total_sum = rdd4.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 35\n",
    "\n",
    "rdd3 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "total_sum = rdd.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 65\n",
    "\n",
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],4)\n",
    "total_sum = rdd4.fold(30, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 165 30*4 + 15 + 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOLD ##\n",
    "\n",
    "\"\"\"\n",
    "•\tfold is similar to reduce in that it is an action that aggregates the elements of an RDD into a single result. However, fold differs from reduce in that it allows you to specify an initial value for the accumulation.\n",
    "•\tfold is an action in PySpark that allows you to aggregate the elements of an RDD using a given function. It takes two arguments: a zero value and a binary operator.\n",
    "\"\"\"\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5]) \n",
    "total_sum = rdd.fold(100, lambda acc, x: acc + x) \n",
    "print(total_sum)  # This Prints 515\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5]) \n",
    "total_sum = rdd.fold(10, lambda acc, x: acc + x) \n",
    "print(total_sum) # This Prints 65\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5]) \n",
    "total_sum = rdd.fold(0, lambda acc, x: acc + x) \n",
    "print(total_sum) # This prints 5*0 + 15 + 0 = 15\n",
    "\n",
    "\n",
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],3)\n",
    "total_sum = rdd4.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This print 10*3 + 15 + 10 = 55 \n",
    "\n",
    "\n",
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],4)\n",
    "total_sum = rdd4.fold(30, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 165  30*4 + 15 + 30 = 165 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],1)\n",
    "total_sum = rdd4.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 35  10*2 + 15 = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "total_sum = rdd3.fold(10, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 65 10*5 + 15 = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = sc.parallelize([1, 2, 3, 4, 5],4)\n",
    "total_sum = rdd4.fold(30, lambda acc, x: acc + x)\n",
    "print(total_sum) # This prints 165 30*4 + 15 + 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc13_'></a>[aggregate(zeroValue)(seqOp, combOp)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "result = rdd.aggregate((0, 0),\n",
    "                       (lambda acc, value: (acc[0] + value, acc[1] + 1)),\n",
    "                       (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])))\n",
    "print(result)  # Output: (10, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc14_'></a>[collectAsMap()](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('b', 2)])\n",
    "result = rdd.collectAsMap()\n",
    "print(result)  # Output: {'a': 1, 'b': 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc15_'></a>[lookup(key)](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('b', 2), ('a', 3)])\n",
    "result = rdd.lookup('a')\n",
    "print(result)  # Output: [1, 3]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
